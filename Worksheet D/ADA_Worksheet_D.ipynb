{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Alu8o67rhyHu"
      },
      "source": [
        "# PES University, Bangalore\n",
        "Established under Karnataka Act No. 16 of 2013"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUL9nH11hyHz"
      },
      "source": [
        "## UE23AM343AB1 - Advanced Data Analytics\n",
        "\n",
        "Designed by Diya M Hande"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvgwZOCfhyH0"
      },
      "source": [
        "### Team\n",
        "-TEAM MEMBERS\n",
        "\n",
        "\n",
        "        -Sai Hemanth Medicherla(SRN:PES2UG23AM088)\n",
        "\n",
        "\n",
        "        -Sai Jaswanth Akula(SRN:PES2UG23AM089)\n",
        "\n",
        "\n",
        "        -Udaya G(SRN:PES2UG23AM111)\n",
        "\n",
        "\n",
        "        -Indira P(SRN:PES2UG23AM072)\n",
        "\n",
        "\n",
        "### Student Details\n",
        "- Name : **SAI HEMANTH MEDICHERLA**\n",
        "- SRN : **PES2UG23AM088**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrB2KkVshyH4"
      },
      "source": [
        "## Worksheet D - Case Study (India & USA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5l2JfSihyH3"
      },
      "source": [
        "### Overview\n",
        "The Student Social Media & Relationships dataset contains anonymized records of students’ social‐media behaviors and related life outcomes. It spans multiple ages and academic levels, focusing on key dimensions such as usage intensity, platform preferences, and relationship dynamics. Each row represents one student’s survey response.\n",
        "\n",
        "You are given two datasets:\n",
        "- `usa_dataset.csv` → Larger dataset (training)\n",
        "- `india_dataset.csv` → Smaller dataset (testing)\n",
        "\n",
        "The USA dataset contains the following variables:\n",
        "- Student_ID: Unique respondent identifier\n",
        "- Age: Age in years\n",
        "- Gender: “Male” or “Female”\n",
        "- Academic_Level: High School / Undergraduate / Graduate\n",
        "- Avg_Daily_Usage_Hours: Average hours per day on social media\n",
        "- Most_Used_Platform:\tInstagram, Facebook, TikTok, etc.\n",
        "- Affects_Academic_Performance: Self‐reported impact on academics (Yes/No)\n",
        "- Sleep_Hours_Per_Night: Average nightly sleep hours\n",
        "- Mental_Health_Score: Self‐rated mental health (1 = poor to 10 = excellent)\n",
        "- Relationship_Status: Single / In Relationship / Complicated\n",
        "- Conflicts_Over_Social_Media:\tNumber of relationship conflicts due to social media\n",
        "- Addicted_Score: Social Media Addiction Score (1 = low to 10 = high)\n",
        "\n",
        "The India dataset contains the same variables, except \"Addicted_Score\" and \"Relationship_Status\" columns are missing. Your task is to predict the addicted score and relationship status for the Indians.\n",
        "\n",
        "### Let’s dive in!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CenzyIZt2UQj"
      },
      "source": [
        "**NOTE:** Please read the questions provided in the case study ppt and follow the mind map provided for the case study if you need any hints."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_MeFUTYzO2m"
      },
      "source": [
        "### Step 1: Load and Inspect the Data\n",
        "- Load both CSV files.\n",
        "- View the first 5 rows of each.\n",
        "- Check shape and data types.\n",
        "- Figure out which variables are categorical and which ones are numerical.\n",
        "- Perform some basic EDA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "oDvZkML_JWwB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0      Instagram\n",
            "1        YouTube\n",
            "2       Facebook\n",
            "3      Instagram\n",
            "4       LinkedIn\n",
            "         ...    \n",
            "607       TikTok\n",
            "608    Instagram\n",
            "609       WeChat\n",
            "610      Twitter\n",
            "611     Facebook\n",
            "Name: Most_Used_Platform, Length: 612, dtype: object\n",
            "0       Twitter\n",
            "1        TikTok\n",
            "2        TikTok\n",
            "3     Instagram\n",
            "4     Instagram\n",
            "        ...    \n",
            "88      Twitter\n",
            "89     Facebook\n",
            "90      Twitter\n",
            "91       TikTok\n",
            "92      Twitter\n",
            "Name: Most_Used_Platform, Length: 93, dtype: object\n",
            "(612, 12) (93, 10)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 612 entries, 0 to 611\n",
            "Data columns (total 12 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   Student_ID                    612 non-null    int64  \n",
            " 1   Age                           612 non-null    int64  \n",
            " 2   Gender                        612 non-null    object \n",
            " 3   Academic_Level                612 non-null    object \n",
            " 4   Avg_Daily_Usage_Hours         612 non-null    float64\n",
            " 5   Most_Used_Platform            612 non-null    object \n",
            " 6   Affects_Academic_Performance  612 non-null    object \n",
            " 7   Sleep_Hours_Per_Night         612 non-null    float64\n",
            " 8   Mental_Health_Score           612 non-null    int64  \n",
            " 9   Relationship_Status           612 non-null    object \n",
            " 10  Conflicts_Over_Social_Media   612 non-null    int64  \n",
            " 11  Addicted_Score                612 non-null    int64  \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 57.5+ KB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 93 entries, 0 to 92\n",
            "Data columns (total 10 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   Student_ID                    93 non-null     int64  \n",
            " 1   Age                           93 non-null     int64  \n",
            " 2   Gender                        93 non-null     object \n",
            " 3   Academic_Level                93 non-null     object \n",
            " 4   Avg_Daily_Usage_Hours         93 non-null     float64\n",
            " 5   Most_Used_Platform            93 non-null     object \n",
            " 6   Affects_Academic_Performance  93 non-null     object \n",
            " 7   Sleep_Hours_Per_Night         93 non-null     float64\n",
            " 8   Mental_Health_Score           93 non-null     int64  \n",
            " 9   Conflicts_Over_Social_Media   93 non-null     int64  \n",
            "dtypes: float64(2), int64(4), object(4)\n",
            "memory usage: 7.4+ KB\n",
            "None None\n",
            "       Student_ID         Age  Avg_Daily_Usage_Hours  Sleep_Hours_Per_Night  \\\n",
            "count  612.000000  612.000000             612.000000             612.000000   \n",
            "mean   348.918301   20.683007               4.686111               7.033824   \n",
            "std    207.807201    1.406382               1.107549               1.045973   \n",
            "min      1.000000   18.000000               1.500000               4.100000   \n",
            "25%    165.750000   20.000000               3.975000               6.300000   \n",
            "50%    345.500000   21.000000               4.600000               7.100000   \n",
            "75%    532.250000   22.000000               5.500000               7.800000   \n",
            "max    705.000000   24.000000               7.300000               9.600000   \n",
            "\n",
            "       Mental_Health_Score  Conflicts_Over_Social_Media  Addicted_Score  \n",
            "count           612.000000                   612.000000      612.000000  \n",
            "mean              6.380719                     2.728758        6.202614  \n",
            "std               1.045834                     0.912698        1.512023  \n",
            "min               4.000000                     0.000000        2.000000  \n",
            "25%               6.000000                     2.000000        5.000000  \n",
            "50%               6.000000                     3.000000        7.000000  \n",
            "75%               7.000000                     3.000000        7.000000  \n",
            "max               9.000000                     5.000000        9.000000          Student_ID        Age  Avg_Daily_Usage_Hours  Sleep_Hours_Per_Night  \\\n",
            "count   93.000000  93.000000              93.000000              93.000000   \n",
            "mean   379.860215  20.505376               6.449462               5.783871   \n",
            "std    172.499061   1.348297               1.105974               1.039052   \n",
            "min      2.000000  19.000000               2.100000               3.800000   \n",
            "25%    237.000000  19.000000               5.600000               5.100000   \n",
            "50%    384.000000  20.000000               6.800000               5.700000   \n",
            "75%    497.000000  22.000000               7.200000               6.100000   \n",
            "max    696.000000  24.000000               8.500000               8.800000   \n",
            "\n",
            "       Mental_Health_Score  Conflicts_Over_Social_Media  \n",
            "count            93.000000                    93.000000  \n",
            "mean              5.215054                     3.645161  \n",
            "std               0.942354                     0.867845  \n",
            "min               4.000000                     0.000000  \n",
            "25%               5.000000                     3.000000  \n",
            "50%               5.000000                     4.000000  \n",
            "75%               6.000000                     4.000000  \n",
            "max               8.000000                     5.000000  \n"
          ]
        }
      ],
      "source": [
        "# code here\n",
        "import pandas as pd #pandas for data manip\n",
        "import numpy as np#numpy for ops\n",
        "import matplotlib.pyplot as plt#for plotting results and all\n",
        "\n",
        "train_df=pd.read_csv('usa_dataset.csv')#this is our train dataset\n",
        "test_df=pd.read_csv('india_dataset.csv')#our test dataset\n",
        "\n",
        "print(train_df.iloc[:,5])#prints first 5 rows\n",
        "print(test_df.iloc[:,5])#prints first 5 rows\n",
        "print(train_df.shape,test_df.shape)#prints shape of dataframes\n",
        "print(train_df.info(),test_df.info())#prints info of dataframes\n",
        "print(train_df.describe(),test_df.describe())#baisic stats\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrHi1ychz3bY"
      },
      "source": [
        "### Step 2: Test Similarity of Distributions\n",
        "Question: Are the two datasets from similar distributions?\n",
        "\n",
        "Hints:\n",
        "- If **numerical features**: Test for normality (Shapiro-Wilk).\n",
        "- If normal → use **parametric tests** (e.g., T-test).\n",
        "- If not normal → use **non-parametric tests** (Mann-Whitney U test).\n",
        "- For more hints → check the case study mind map\n",
        "\n",
        "Do this for at least two numerical features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7Eb7h94g0Y8A"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Addicted score is not normally distributed\n",
            "Mann-Whitney U result: 4.372527922988039e-20 44706.0\n",
            "Daily usage is not normally distributed\n",
            "Mann-Whitney U result: 4.56761229612571e-31 7254.0\n"
          ]
        }
      ],
      "source": [
        "# code here\n",
        "from scipy.stats import shapiro, ttest_ind, mannwhitneyu\n",
        "#These 3 libraries have our tests that we need to perform \n",
        "stat1_train, p_train=shapiro(train_df['Mental_Health_Score'])\n",
        "stat2_train,p_train2=shapiro(train_df['Avg_Daily_Usage_Hours'])\n",
        "stat1_test, p_test=shapiro(test_df['Mental_Health_Score'])\n",
        "stat2_test,p_test2=shapiro(test_df['Avg_Daily_Usage_Hours'])\n",
        "# Check normality for Addicted Score\n",
        "if p_train > 0.05 and p_test > 0.05:\n",
        "    print(\"Addicted score is normally distributed\")\n",
        "    stat, p = ttest_ind(train_df['Mental_Health_Score'], test_df['Mental_Health_Score'])\n",
        "    print(\"T-test result:\", p, stat)\n",
        "else:\n",
        "    print(\"Addicted score is not normally distributed\")\n",
        "    stat, p = mannwhitneyu(train_df['Mental_Health_Score'], test_df['Mental_Health_Score'])\n",
        "    print(\"Mann-Whitney U result:\", p, stat)\n",
        "\n",
        "\n",
        "# Check normality for Daily Usage\n",
        "if p_train2 > 0.05 and p_test2 > 0.05:\n",
        "    print(\"Daily usage is normally distributed\")\n",
        "    stat, p = ttest_ind(train_df['Avg_Daily_Usage_Hours'], test_df['Avg_Daily_Usage_Hours'])\n",
        "    print(\"T-test result:\", p, stat)\n",
        "else:\n",
        "    print(\"Daily usage is not normally distributed\")\n",
        "    stat, p = mannwhitneyu(train_df['Avg_Daily_Usage_Hours'], test_df['Avg_Daily_Usage_Hours'])\n",
        "    print(\"Mann-Whitney U result:\", p, stat)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhSk63Na0Ze9"
      },
      "source": [
        "### Step 3: Correlated Numerical Features\n",
        "- Use **Pearson correlation** for numerical features.\n",
        "- Remove one of the variables if correlation > threshold (ex: 0.8, only if required)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "zbb2TLnE0sCn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Mental_Health_Score', 'Sleep_Hours_Per_Night', 'Conflicts_Over_Social_Media', 'Addicted_Score'}\n"
          ]
        }
      ],
      "source": [
        "# code here\n",
        "threshold=0.5#threshold value\n",
        "to_drop=set()#set of columns to drop\n",
        "corr_matrix=train_df.corr(method='pearson',numeric_only=True)#correlation matrix\n",
        "for i in range(len(corr_matrix.columns)):\n",
        "    for j in range(i+1,len(corr_matrix.columns)):\n",
        "        corr_value=corr_matrix.iloc[i,j]\n",
        "        if abs(corr_value)>threshold:\n",
        "            to_drop.add(corr_matrix.columns[j])\n",
        "print(to_drop)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5WLlcAE0saS"
      },
      "source": [
        "### Step 4: Correlated Categorical Features\n",
        "- Use **Chi-square test of independence** for categorical-categorical pairs.\n",
        "- Build a contingency table for each pair."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "fEABMorF079k"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('Gender', 'Academic_Level'), ('Gender', 'Most_Used_Platform'), ('Academic_Level', 'Most_Used_Platform'), ('Academic_Level', 'Affects_Academic_Performance'), ('Academic_Level', 'Relationship_Status'), ('Most_Used_Platform', 'Affects_Academic_Performance'), ('Most_Used_Platform', 'Relationship_Status'), ('Affects_Academic_Performance', 'Relationship_Status')]\n"
          ]
        }
      ],
      "source": [
        "# code here\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "\n",
        "cat_cols = train_df.select_dtypes(include='object').columns\n",
        "most_related=[]\n",
        "\n",
        "for i in range(len(cat_cols)):\n",
        "    for j in range(i+1, len(cat_cols)):\n",
        "        col1 = cat_cols[i]\n",
        "        col2 = cat_cols[j]\n",
        "        table = pd.crosstab(train_df[col1], train_df[col2])\n",
        "        # Perform Chi-square test\n",
        "        chi2, p, dof, expected = chi2_contingency(table)\n",
        "        #print(f\"{col1} vs {col2}: p-value={p}\")\n",
        "        if p < 0.05:\n",
        "            most_related.append((col1, col2))\n",
        "print(most_related)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQfesuzz08Wb"
      },
      "source": [
        "### Step 5: Significance of Numerical Features vs Label\n",
        "- If label has 2 categories → Use **point biserial correlation** (not in the syllabus, but in the textbook).\n",
        "- If label has >2 categories → Use **ANOVA** (if parametric) or **Kruskal-Wallis** (if non-parametric).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPtquIVD2193"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Student_ID vs Gender: stat=-0.0010276362037785688, p=0.9797595616870317\n",
            "Student_ID vs Affects_Academic_Performance: stat=0.011649942463995068, p=0.7736344065361943\n",
            "Age vs Gender: stat=0.46962734515999954, p=6.76577086516803e-35\n",
            "Age vs Affects_Academic_Performance: stat=-0.11755552501696737, p=0.003587532775806306\n",
            "Avg_Daily_Usage_Hours vs Gender: stat=0.006425663610800214, p=0.8739534631537998\n",
            "Avg_Daily_Usage_Hours vs Affects_Academic_Performance: stat=0.6671184125169828, p=4.810181978417886e-80\n",
            "Sleep_Hours_Per_Night vs Gender: stat=-0.05522739367605889, p=0.172410689158084\n",
            "Sleep_Hours_Per_Night vs Affects_Academic_Performance: stat=-0.5988605996393472, p=7.903463812010811e-61\n",
            "Mental_Health_Score vs Gender: stat=-0.02479926296081962, p=0.5403129500996003\n",
            "Mental_Health_Score vs Affects_Academic_Performance: stat=-0.8168778819338094, p=6.712462775935003e-148\n",
            "Conflicts_Over_Social_Media vs Gender: stat=-0.037853845351101784, p=0.349853747221319\n",
            "Conflicts_Over_Social_Media vs Affects_Academic_Performance: stat=0.8384305212419108, p=6.184820146893604e-163\n",
            "Addicted_Score vs Gender: stat=0.028514279813650796, p=0.48136715832983273\n",
            "Addicted_Score vs Affects_Academic_Performance: stat=0.8850682946178545, p=9.350632625752023e-205\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import pointbiserialr\n",
        "\n",
        "# Identify numerical and binary categorical columns\n",
        "numerical_cols = train_df.select_dtypes(include='number').columns\n",
        "binary_cols = [col for col in train_df.columns if train_df[col].nunique() == 2 and train_df[col].dtype == 'object']\n",
        "\n",
        "for num_col in numerical_cols:\n",
        "    for bin_col in binary_cols:\n",
        "        # Encode binary categorical column to numeric\n",
        "        bin_encoded = train_df[bin_col].astype('category').cat.codes\n",
        "        stat, p = pointbiserialr(train_df[num_col], bin_encoded)\n",
        "        print(f\"{num_col} vs {bin_col}: stat={stat}, p={p}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP9atUU_3TmM"
      },
      "source": [
        "### Step 6: Select the Most Significant Features\n",
        "- Drop features that are highly correlated or not statistically significant (only if required).\n",
        "- Keep the best set for model training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ZV6tfSNk3TLi"
      },
      "outputs": [],
      "source": [
        "# code here\n",
        "\n",
        "#already done in step 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WsMiP-Q3aVQ"
      },
      "source": [
        "### Step 7: Train and Predict\n",
        "- Train models on USA dataset (Hint: regression model for numerical data and classification model for categorical data).\n",
        "- Predict missing variables in India dataset.\n",
        "- Evaluate model performance.\n",
        "- Create a submission.csv file that contains your predictions in the format:\n",
        "\n",
        "Student_ID, Relationship_Status, Addicted_Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-m2Ipa83a48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saved \n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Features to encode (do NOT include target columns)\n",
        "trans_ft = ['Gender', 'Most_Used_Platform']\n",
        "\n",
        "# Drop only columns that exist (avoids KeyError if already dropped)\n",
        "drop_cols = [col for col in ['Relationship_Status', 'Addicted_Score'] if col in train_df.columns]\n",
        "X_train = train_df.drop(columns=drop_cols)\n",
        "X_test = test_df.copy()  # test set does not have targets\n",
        "\n",
        "# Build preprocessor for categorical and numerical features\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(drop='first'), trans_ft),\n",
        "        ('num', StandardScaler(), X_train.select_dtypes(include='number').columns)\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "# Transform features\n",
        "x_train = preprocessor.fit_transform(X_train)\n",
        "x_test = preprocessor.transform(X_test)\n",
        "\n",
        "# Targets (check if columns exist)\n",
        "y_relationship = train_df['Relationship_Status'] if 'Relationship_Status' in train_df.columns else None\n",
        "y_addicted = train_df['Addicted_Score'] if 'Addicted_Score' in train_df.columns else None\n",
        "\n",
        "# Train models only if targets exist\n",
        "if y_addicted is not None:\n",
        "    regressor = LinearRegression()\n",
        "    regressor.fit(x_train, y_addicted)\n",
        "    y_addicted_pred = regressor.predict(x_test)\n",
        "else:\n",
        "    y_addicted_pred = None\n",
        "\n",
        "if y_relationship is not None:\n",
        "    classifier = RandomForestClassifier(random_state=42)\n",
        "    classifier.fit(x_train, y_relationship)\n",
        "    y_relationship_pred = classifier.predict(x_test)\n",
        "else:\n",
        "    y_relationship_pred = None\n",
        "\n",
        "# Print predictions (optional)\n",
        "#print(\"Relationship_Status predictions:\", y_relationship_pred)\n",
        "#print(\"Addicted_Score predictions:\", y_addicted_pred)\n",
        "\n",
        "\n",
        "output_df = pd.DataFrame({\n",
        "    'Student_ID': test_df['Student_ID'],\n",
        "    'Relationship_Status': y_relationship_pred,\n",
        "    'Addicted_Score': y_addicted_pred\n",
        "})\n",
        "\n",
        "# Save to CSV\n",
        "output_df.to_csv('ind_pred.csv', index=False)\n",
        "print('saved ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#to predict the accuracy of the model \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLIt2nJt7H8S"
      },
      "source": [
        "### Q&A\n",
        "Answer the following based on your analysis:\n",
        "1. Which numerical features are correlated?\n",
        "2. Which categorical features are correlated?\n",
        "3. Which features are most significant for the model?\n",
        "4. Are USA and India distributions similar?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6856F9u7J2n"
      },
      "source": [
        "**Answer Here**\n",
        "\n",
        "1) Mental_Health_Score', 'Sleep_Hours_Per_Night', 'Conflicts_Over_Social_Media', 'Addicted_Score'\n",
        "2)'Gender', 'Academic_Level'), ('Gender', 'Most_Used_Platform'), ('Academic_Level', 'Most_Used_Platform'), ('Academic_Level', 'Affects_Academic_Performance'), ('Academic_Level', 'Relationship_Status'), ('Most_Used_Platform', 'Affects_Academic_Performance'), ('Most_Used_Platform', 'Relationship_Status'), ('Affects_Academic_Performance', 'Relationship_Status') are categorically coorelated by chi sq\n",
        "\n",
        "3) All the highly correlated features are Mental_Health_Score\n",
        "Sleep_Hours_Per_Night\n",
        "Conflicts_Over_Social_Media\n",
        "Avg_Daily_Usage_Hours\n",
        "Gender\n",
        "Most_Used_Platform\n",
        "Academic_Level\n",
        "Affects_Academic_Performance\n",
        "\n",
        "technically we are supposed to drop addicted score but since it is a feature to be predicted, we don't\n",
        "we can drop student ID.\n",
        "\n",
        "\n",
        "4) Some of the features are similar yes, some of them have really similar distributions like we can see in step 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
